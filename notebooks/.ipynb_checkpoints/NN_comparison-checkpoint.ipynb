{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we are going to compare a normal scikit NN regressor with its implementation on pytorch. Something is off so lets figure it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Net2layers(nn.Module):\n",
    "    def __init__(self, input_size, l1_size, l2_size):\n",
    "        super(Net2layers, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, l1_size)\n",
    "        self.fc2 = nn.Linear(l1_size, l2_size)\n",
    "        self.fc3 = nn.Linear(l2_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, df, feature_columns, device):\n",
    "        m, n = df[feature_columns].shape\n",
    "        x = torch.Tensor(df[feature_columns].values).to(device)\n",
    "        output = self.forward(x)\n",
    "        return output.detach().numpy()\n",
    "    \n",
    "def get_tensors(df, feature_columns, target_name, BS, device=\"cpu\"):\n",
    "    m, n = df[feature_columns].shape\n",
    "    x_all = torch.Tensor(df[feature_columns].values).to(device)\n",
    "    y_all = torch.Tensor(df[target_name].values).to(device)\n",
    "    x = x_all.reshape([-1, BS, n] )\n",
    "    y = y_all.reshape([-1, BS, 1] )\n",
    "    return x, y\n",
    "    \n",
    "def train_scikit(\n",
    "    df_train,\n",
    "    learning_rate,\n",
    "    batch_size,\n",
    "    n_iter,\n",
    "    l1_size,\n",
    "    l2_size,\n",
    "    input_size\n",
    "):\n",
    "    model = MLPRegressor(\n",
    "    hidden_layer_sizes=(l1_size,l2_size),\n",
    "    random_state=1,\n",
    "    verbose=False,\n",
    "    max_iter=n_iter,\n",
    "    tol=1e-10,\n",
    "    learning_rate_init=learning_rate,\n",
    "    batch_size=batch_size)\n",
    "    \n",
    "    model.fit(X=df_train[[\"x\",\"y\"]], y=df_train[\"target\"])\n",
    "    return model\n",
    "    #return model.predict(df_train[[\"x\", \"y\"]]), model\n",
    "    \n",
    "\n",
    "def train_pytorch(\n",
    "    df_train,\n",
    "    learning_rate,\n",
    "    batch_size,\n",
    "    n_iter,\n",
    "    l1_size,\n",
    "    l2_size,\n",
    "    input_size,\n",
    "    device\n",
    "):\n",
    "    model = Net2layers(input_size=input_size, l1_size = l1_size, l2_size=l2_size).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optm = Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "    x, y = get_tensors(df_train,[\"x\", \"y\"], \"target\", batch_size, device)\n",
    "\n",
    "    for i in range(n_iter):\n",
    "\n",
    "        optm.zero_grad()\n",
    "        output = model(x)\n",
    "        loss = criterion(output,y)\n",
    "        loss.backward()\n",
    "        optm.step()\n",
    "    return model\n",
    "    #return model.predict(df_train, [\"x\", \"y\"]), model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "learning_rate=0.001\n",
    "batch_size=100\n",
    "n_iter = 200\n",
    "sample_size = 100000\n",
    "l1_size = 10\n",
    "l2_size = 5\n",
    "input_size = 2\n",
    "dev=\"cpu\"\n",
    "device = device = torch.device(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(\n",
    "    data={\"x\": np.linspace(1,10,sample_size),\n",
    "          \"y\": np.linspace(1,10,sample_size), \"target\": np.linspace(1,10,sample_size)*np.linspace(1,10,sample_size)\n",
    "         })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 36.7 s, sys: 121 ms, total: 36.8 s\n",
      "Wall time: 36.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPRegressor(batch_size=100, hidden_layer_sizes=(10, 5), random_state=1,\n",
       "             tol=1e-10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time train_scikit(df_train,learning_rate, batch_size,n_iter,l1_size,l2_size,input_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.65 s, sys: 77.8 ms, total: 2.73 s\n",
      "Wall time: 1.77 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Net2layers(\n",
       "  (fc1): Linear(in_features=2, out_features=10, bias=True)\n",
       "  (fc2): Linear(in_features=10, out_features=5, bias=True)\n",
       "  (fc3): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time train_pytorch(df_train,learning_rate, batch_size,n_iter,l1_size,l2_size,input_size, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPRegressor(\n",
    "    hidden_layer_sizes=(l1_size,l2_size),\n",
    "    random_state=1,\n",
    "    verbose=False,\n",
    "    max_iter=n_iter,\n",
    "    tol=1e-10,\n",
    "    learning_rate_init=learning_rate,\n",
    "    batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPRegressor(batch_size=1, hidden_layer_sizes=(10, 5), learning_rate_init=0.01,\n",
       "             max_iter=1000, random_state=1, tol=1e-10)"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=df_train[[\"x\",\"y\"]], y=df_train[\"target\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.47960814, -0.47960814,  4.57565213, 16.40694518, 28.23823823,\n",
       "       41.11501509, 55.0584445 , 69.00187391, 82.94530332, 96.88873273])"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(df_train[[\"x\", \"y\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch\n",
    "from __future__ import print_function\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Net2layers(nn.Module):\n",
    "    def __init__(self, input_size, l1_size, l2_size):\n",
    "        super(Net2layers, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, l1_size)\n",
    "        self.fc2 = nn.Linear(l1_size, l2_size)\n",
    "        self.fc3 = nn.Linear(l2_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def predict(self, df, feature_columns):\n",
    "        m, n = df[feature_columns].shape\n",
    "        x = torch.Tensor(df[feature_columns].values)\n",
    "        output = self.forward(x)\n",
    "        return output.detach().numpy()\n",
    "    \n",
    "def get_tensors(df, feature_columns, target_name, BS, device=\"cpu\"):\n",
    "    m, n = df[feature_columns].shape\n",
    "    x_all = torch.Tensor(df[feature_columns].values).to(device)\n",
    "    y_all = torch.Tensor(df[target_name].values).to(device)\n",
    "    x = x_all.reshape([-1, BS, n] )\n",
    "    y = y_all.reshape([-1, BS, 1] )\n",
    "    return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    }
   ],
   "source": [
    "model = Net2layers(input_size=input_size, l1_size = l1_size, l2_size=l2_size).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "EPOCHS = n_iter\n",
    "optm = Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "x, y = get_tensors(df_train,[\"x\", \"y\"], \"target\", batch_size, device )\n",
    "print(x.get_device())\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    \n",
    "    optm.zero_grad()\n",
    "    output = model(x)\n",
    "    loss = criterion(output,y)\n",
    "    loss.backward()\n",
    "    optm.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.5300847],\n",
       "       [-0.5300847],\n",
       "       [ 2.0356202],\n",
       "       [15.027582 ],\n",
       "       [28.019545 ],\n",
       "       [41.011505 ],\n",
       "       [54.003468 ],\n",
       "       [66.99543  ],\n",
       "       [79.9874   ],\n",
       "       [92.97936  ]], dtype=float32)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(df_train, [\"x\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `model.predict()` not found.\n"
     ]
    }
   ],
   "source": [
    "?model.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      1.0\n",
       "1      4.0\n",
       "2      9.0\n",
       "3     16.0\n",
       "4     25.0\n",
       "5     36.0\n",
       "6     49.0\n",
       "7     64.0\n",
       "8     81.0\n",
       "9    100.0\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"target\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trading-bot",
   "language": "python",
   "name": "trading-bot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
